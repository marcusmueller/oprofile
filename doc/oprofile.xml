<?xml version="1.0" encoding='ISO-8859-1'?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN" "http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd">

<book id="oprofile-guide">
<bookinfo>
	<title>oprofile manual</title>
 
	<authorgroup>
		<author>
			<firstname>John</firstname>
			<surname>Levon</surname>
			<affiliation>
				<address><email>levon@movementarian.org</email></address>
			</affiliation>
		</author>
	</authorgroup>

	<copyright>
		<year>2000-2002</year>
		<holder>Victoria University of Manchester, John Levon and others</holder>
	</copyright>

</bookinfo>

<toc></toc>

<chapter id="introduction">
<title>Introduction</title>

<para>
oprofile is a profiling system for Linux 2.2/2.4/2.6 systems on a number of architectures. It is capable of profiling
all parts of a running system, from the kernel (including modules and interrupt handlers) to shared libraries
to binaries. It runs transparently in the background collecting information at a low overhead. These
features make it ideal for profiling entire systems to determine bottle necks in real-world systems.
</para>

<sect1 id="requirements">
<title>System requirements</title>

<variablelist>
	<varlistentry>
		<term>Linux kernel 2.2/2.4</term>
		<listitem>
			oprofile uses a kernel module that can be compiled for
			2.2.11 or later and 2.4. Versions 2.4.10 or above are recommended, and required if you use the
			boot-time kernel option <option>nosmp</option>. AMD Hammer support requires a recent (&ge; 2.4.19) kernel
			with the line <constant>EXPORT_SYMBOL(do_fork);</constant> present in <filename>kernel/ksyms.c</filename>.
			Such a kernel is present in the <ulink url="http://www.x86-64.org">x86-64.org</ulink> CVS repository.
			2.5 kernels are supported with the in-kernel oprofile driver.
<!-- FIXME: do we require always gte 2.4.10 for nosmp ? -->
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>modutils 2.4.6 or above</term>
		<listitem>
			You should have installed modutils 2.4.6 or higher (in fact earlier versions work well in almost all
			cases).
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Intel P6 processor, Pentium 4 / Xeon, AMD Athlon/Duron, AMD Hammer, or
		Intel Itanium 2.</term>
		<listitem>
			For Intel IA32, a CPU with either a P6 generation or Pentium 4 core is
			required. In marketing terms this translates to anything
			between an Intel Pentium Pro (not Pentium Classics) and
			a Pentium 4 / Xeon, including all Celerons.  The AMD
			Athlon, Duron, and Hammer CPUs are also supported.  Other IA32
			CPU types only support the RTC mode of oprofile; please
			see later in this manual for details.  The Itanium 2
			support uses the performance monitor unit in the processor.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Uniprocessor or SMP</term>
		<listitem>
			SMP machines are also supported in both Intel and AMD variants.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Required libraries</term>
		<listitem>
			These libraries are required : <filename>popt</filename>, <filename>bfd</filename>,
			<filename>liberty</filename> (debian users: libiberty is provided in binutils-dev package), <filename>dl</filename>
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Bash version 2</term>
		<listitem>
			The <command>opcontrol</command> script requires bash version 2 at least to be installed
			as <filename>/bin/bash</filename> or <filename>/bin/bash2</filename>
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>oprofile GUI</term>
		<listitem>
			The use of the GUI to start the profiler requires the <filename>Qt 2</filename> library. Qt 3 should
			also work.
		</listitem>
	</varlistentry>
	<varlistentry>
 		<term><acronym>ELF</acronym></term>
		<listitem>
			Probably not too strenuous a requirement, but older <acronym>A.OUT</acronym> binaries/libraries are not supported.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>K&amp;R coding style</term>
		<listitem>
			OK, so it's not really a requirement, but I wish it was...
		</listitem>
	</varlistentry>
</variablelist>


</sect1>

<sect1 id="resources">
<title>Internet resources</title>

<variablelist>
	<varlistentry>
		<term>Web page</term>
		<listitem>
			There is a web page (which you may be reading now) at
			<ulink url="http://oprofile.sf.net/">http://oprofile.sf.net/</ulink>.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Download</term>
		<listitem>
			You can download a source tarball or get anonymous CVS at the sourceforge page,
			<ulink url="http://sf.net/projects/oprofile/">http://sf.net/projects/oprofile/</ulink>.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Mailing list</term>
		<listitem>
			There is a very low-traffic oprofile-specific mailing list, details at
			<ulink url="http://sf.net/mail/?group_id=16191">http://sf.net/mail/?group_id=16191</ulink>.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>Bug tracker</term>
		<listitem>
			There is a bug tracker for oprofile at SourceForge,
			<ulink url="http://sf.net/tracker/?group_id=16191&amp;atid=116191">http://sf.net/tracker/?group_id=16191&amp;atid=116191</ulink>.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term>IRC channel</term>
		<listitem>
			Several oprofile developers and users sometimes hang out on channel <command>#oprofile</command>
			on the <ulink url="http://freenode.info">freenode</ulink> network. 
		</listitem>
	</varlistentry>
</variablelist>

</sect1>

<sect1 id="install">
<title>Installation</title>

First you need to build oprofile and install it. <command>./configure</command>, <command>make</command>, <command>make install</command>
is all you need, but note these arguments to <command>./configure</command> :
<variablelist>
	<varlistentry>
		<term><option>--with-linux</option></term>
		<listitem>
			Use this option to specify the location of the kernel source tree you wish
			to compile against. The kernel module is built against this source and
			will only work with a running kernel built from the same source with
			similar options, so it is important you specify this option if you need
			to.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--with-kernel-support</option></term>
		<listitem>
			Use this option with linux 2.5 kernel to indicate the 
	    		kernel provides the oprofile device driver.
		</listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--with-qt-dir/includes/libraries</option></term>
		<listitem>
			Specify the location of Qt headers and libraries. It defaults to searching in
			<constant>$QTDIR</constant> if these are not specified.
		</listitem>
	</varlistentry>
	<varlistentry id="enable-abi">
		<term><option>--enable-abi</option></term>
		<listitem>
			Activate code within the oprofile sample collection daemon
			<command>oprofiled</command> which records information about the binary
			format of sample files in <filename>/var/lib/oprofile/abi</filename>, to
			permit their transport between hosts using the
			<command>op_import</command> utility. See <xref
			linkend="op-import" />. This option is primarily intended for embedded
			systems or remote analysis of production machines; if you will be
			performing all sample analysis on the same machine as you are profiling,
			it is safe to omit this option.
		</listitem>
	</varlistentry>
</variablelist>
<para>
You'll need to have a configured kernel source for the current kernel
to build the module.  It is also recommended that if you have a
uniprocessor machine, you enable the local APIC / IO_APIC support for
your kernel (this is automatically enabled for SMP kernels).  On
machines with power management, such as laptops, the power management
must be turned off when using oprofile. The power management software
in the BIOS cannot handle the non-maskable interrupts (NMIs) used by
oprofile for data collection. If you use the nmi watchdog be warned than
watchdog is disabled when profiling starts, and not re-enabled until the
oprofile module is removed. If you compile oprofile for
a 2.2 kernel you must be root to compile the module. If you are using
2.5 kernels or higher, you do not need kernel source, as long as the
oprofile driver is enabled; additionally, you should not need to disable
power management.
</para>

</sect1>

<sect1 id="uninstall">
<title>Uninstalling oprofile</title>
<para>
You must have the source tree available to uninstall oprofile; a <command>make uninstall</command> will
remove all installed files except your configuration file in the directory <filename>~/.oprofile</filename>.
</para>
</sect1>

</chapter>

<chapter id="overview"> 
<title>Overview of oprofile tools</title>
<para>
This section gives a brief description of the available oprofile utilities and their purpose.
</para>
<variablelist>
<varlistentry>
	<term><filename>op_help</filename></term>
	<listitem>
		This utility lists the available events and short descriptions.
	</listitem>
</varlistentry>
	
<varlistentry>
	<term><filename>opcontrol</filename></term>
	<listitem>
		Used for controlling the oprofile data collection, discussed in <xref linkend="usage" />.
	</listitem>
</varlistentry>

<varlistentry>
	<term><filename>oprofpp</filename></term>
	<listitem><para>
		This is the main tool for retrieving useful profile data, described in
		<xref linkend="results" />.
	</para></listitem>
</varlistentry>

<varlistentry>
	<term><filename>op_time</filename></term>
	<listitem><para>
		This utility is useful for examining the relative profile values for
		all images on the system to determine the applications with the largest
		impact on system performance.
	</para></listitem>
</varlistentry>

<varlistentry>
	<term><filename>op_to_source</filename></term>
	<listitem><para>
		This utility can be used to produce annotated source, assembly or mixed source/assembly.
		Source level annotation is available only if the application was compiled with 
		debugging symbols. See <xref linkend="op-to-source" />.
	</para></listitem>
</varlistentry>

<varlistentry>
	<term><filename>op_merge</filename></term>
	<listitem><para>
		This utility is useful to merge samples files which belongs to the same application
		especially when you profile with separating samples for shared libs. See <xref linkend="op-merge" />.
	</para></listitem>
</varlistentry>

<varlistentry id="op-import">
	<term><filename>op_import</filename></term>
	<listitem><para>
		This utility converts sample database files from a foreign binary format (abi) to
		the native format. This is useful only when moving sample files between hosts,
		for analysis on platforms other than the one used for collection. The abi format
		of the file to be imported is described in a text file located in
		<filename>/var/lib/oprofile/abi</filename>, if the <option>--enable-abi</option>
		configure-time option was enabled. Furthermore, the <command>op_import</command>
		tool is not built unless <option>--enable-abi</option> is given. See <xref
		linkend="enable-abi" />.
	</para></listitem>
</varlistentry>

</variablelist>
	
</chapter>
 
<chapter id="usage">
<title>Usage</title>

<sect1 id="typical">
<title>A typical session</title>
<para>
Before getting into detail about usage, it's probably a good idea to have a quick stroll through an example
session (this example is for Intel P6 generation processors, but the process is the same).
</para>
<para>
First we need to start the profiler running in the background. We need to pass the correct
<filename>vmlinux</filename> file to the daemon (to allow kernel profiling), and we need to specify what event to count and the counter value.
Here I've started with :
</para>
<para>
<command>opcontrol --setup --vmlinux=/boot/2.4.0ac12/vmlinux  --ctr0-event=CPU_CLK_UNHALTED --ctr0-count=600000</command>
</para><para>
<command>opcontrol --start</command>
</para>
<para>
Here we've enabled counter 0 to count "CPU_CLK_UNHALTED" (number of cycles CPU is not halted) events with a count value of 600,000.
This event is useful as profiles resulting generally correspond to time-spent profiles for functions etc. 
</para>
<para>
A quick <command>ps ax</command> confirms that the daemon (<command>oprofiled</command>) has started.
Data is now being collected in the kernel. Now we can do whatever we like ... although in this case I'm profiling the C++ application
<ulink url="http://www.lyx.org/">LyX</ulink>.
Note that unlike <command>gprof</command>, no instrumentation (<option>-pg</option> and <option>-a</option> options to <command>gcc</command>)
is necessary. This is major factor in achieving the low overhead of oprofile. Compiling with debug symbols (the <option>-g</option>
option) is not necessary to get a basic function-based profile listing, but it must be used in order to retrieve line number
information and create annotated source. See the FAQ <xref linkend="symbol-and-debug-info" /> about debug information vs symbol information.
</para>
<para>
Rather than wait for the buffers to fill up, I now force the profiling data to be processed with :
</para>
<para><command>opcontrol --dump</command></para>
<para>
which will ask the kernel module to dump as much data as it can to the daemon.
</para>
<note>
<para>Forcing a dump like this can cause the daemon to become very busy, especially the first time it is done. Don't worry,
that's not normal behaviour; so if you are profiling over a larger period of time, such spikes won't appear.
</para>
</note>
<para>
I can now ask for a symbol-based summary of the sample profile :
</para>
<para><command>oprofpp --demangle -l ./lyx &gt;oprof.out</command></para>
<para>
This can be quite slow on large binaries, so sit tight. 
As it's a C++ program, I asked for the symbols to be demangled to a readable form. Examining
the output will give the symbols against which the most hits were registered. In this case I got :
</para>
<screen>
...
Row::par(void)[0x0813ab54]: 5.4079% (472 samples)
LyXText::GetRow(LyXParagraph *, int, int &amp;) const[0x08170a4c]: 5.5683% (486 samples)
LyXParagraph::GetFontSettings(BufferParams const &amp;, int) const[0x08145420]: 5.7516% (502 samples)
Row::next(void) const[0x0813ac24]: 15.4904% (1352 samples)
</screen> 
<para>
at the top. Note that over a longer run (or with a lower <option>ctr0-count</option> value) the number of samples will 
be much more statistically
reliable. Note that these sample counts do <emphasis>not</emphasis> necessarily reflect the relative amounts of time
spent in each function - it depends on the event being counted. In this case we used <constant>CPU_CLK_UNHALTED</constant>
which the command <command>opcontrol --list-events</command> tells us is "clocks processor is not halted", so in fact is likely to represent
the relative time spent accurately (in fact, experiments have shown that using this event is far more accurate than the values
produced by <command>gprof</command>).
</para>
<note>
<para>
If you're more used to <command>gprof</command> style profile output, you can use <command>oprofpp -g gmon.out</command> and then
<command>gprof -p binary</command> to get flat profiles. oprofile does not (cannot) support the call graph
feature of <command>gprof</command>.
</para>
</note>

</sect1>

<sect1 id="controlling-daemon">
<title>Controlling oprofile data collection with the <command>opcontrol</command> script</title>
<para>
In this section we describe the configuration and control of the profiling system with opcontrol in more depth.
</para>
<para>
The <command>opcontrol</command> script provides the following options :
</para>
<variablelist>
	<varlistentry>
		<term><option>--init</option></term>
		<listitem><para>
		Loads the oprofile module if required and makes the oprofile driver
		interface available.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--setup</option></term>
		<listitem><para>
		    Followed by list arguments for profiling set up. List of arguments
		    saved in <filename>/home/root/.oprofile/daemonrc</filename>.
		  </para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--start</option></term>
		<listitem><para>
		    Start data collection with either arguments provided by <option>--setup</option>
		of information saved in <filename>/home/root/.oprofile/daemonrc</filename>. Specifying
		the addition <option>--verbose</option> makes the daemon generate lots of debug data
		whilst it is running.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--dump</option></term>
		<listitem><para>
		    Force a flush of the collected profiling data to the daemon.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--stop</option></term>
		<listitem><para>
		    Stop data collection (this separate step is not possible with 2.2 or 2.4 kernels).
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--shutdown</option></term>
		<listitem><para>
		    Stop data collection and remove daemon.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--reset</option></term>
		<listitem><para>
		    Clears out data from current session, but leaves saved sessions.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--save=</option>session_name</term>
		<listitem><para>
		    Save data from current session to session_name.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--deinit</option></term>
		<listitem><para>
                Shuts down daemon. Unload the oprofile module and oprofilefs.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--list-events</option></term>
		<listitem><para>
		    List event types and unit masks.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--help</option></term>
		<listitem><para>
		    Generate usage messages.
		</para></listitem>
	</varlistentry>
</variablelist>

<para>
The <command>opcontrol</command> script options used with the
	<option>--setup</option> option :
</para>
<variablelist>
	<varlistentry>
		<term><option>--buffer-size=</option>num</term>
		<listitem><para>
		Number of samples in kernel buffer.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--ctrN-event=</option>name</term>
		<listitem><para>
		Set counter N to measure symbolic event name.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--ctrN-count=</option>val</term>
		<listitem><para>
		Number of events between samples for counter N.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--ctrN-unit-mask=</option>val</term>
		<listitem><para>
		Set unit mask for counter N (e.g. --ctr0-unit-mask=0xf)
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--ctrN-kernel=</option>[0|1]</term>
		<listitem><para>
		Whether to count kernel events for counter N.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--pid-filter=</option>pid</term>
		<listitem><para>
		Only profile process pid  (only available for 2.4 version).
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--pgrp-filter=</option>pgrp</term>
		<listitem><para>
		Only profile process tty group pgrp (only avilable for 2.4 version)
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--separate-samples</option></term>
		<listitem><para>
		Separate samples for each distinct application shared library.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--vmlinux=</option>file</term>
		<listitem><para>
		vmlinux kernel image.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--kernel-range=</option>start,end</term>
		<listitem><para>
		kernel range vma address in hexadecimal.
		</para></listitem>
	</varlistentry>
</variablelist>

</sect1>
 
<sect1 id="oprofile-gui">
<title>Starting profiling from the <command>oprofile</command> GUI</title>
<para>
This section describes the <command>oprofile</command> Qt-based interface.
</para>
<para>
The <command>oprof_start</command> application provides a convenient way to start the profiler.
Note that <command>oprof_start</command> is just a wrapper around the <command>opcontrol</command> script,
so it does not provide more services than the script itself.
</para>
<para>
After <command>oprof_start</command> is started you can select the event type for each counter;
the sampling rate and other related parameters are explained in <xref linkend="controlling-daemon" />.
The "Configuration" section allows you to set general parameters such as the buffer size, kernel filename
etc. The counter setup interface should be self-explanatory; <xref linkend="hardware-counters" /> and related 
links contain information on using unit masks.
</para>
<para>
A status line shows the current status of the profiler: how long it has been running, and the average
number of interrupts received per second and the total, over all processors.
Note that quitting <command>oprof_start</command> does not stop the profiler.
</para>
<para>
Your configuration is saved when you quit the gui in two files in ~/.oprofile directory :
<filename>oprof_start_config</filename> and <filename>oprof_start_event</filename>. These
contain the general configuration, and event/counter setup, respectively.
</para>

</sect1>

<sect1 id="sessions">
<title>Profiling sessions</title>
<para>
It can often be useful to split up profiling data into several different
time periods. For example, you may want to collect data on an application's
startup separately from the normal runtime data. You can use the simple
command <command>opcontrol --save</command> to do this. For example :
</para>
<screen>
opcontrol --save=blah
</screen>
<para>
will create a sub-directory in <filename>/var/lib/oprofile/samples</filename> containing the samples
up to that point (the current session's sample files are moved into this
directory). You can then pass this name as, for example, a parameter to
<command>op_time</command> to only get data up to the point you named the
session.
</para>
</sect1>
 
<sect1 id="detailed-parameters">
<title>Configuration details</title>

<sect2 id="hardware-counters">
<title>Hardware Performance Counters</title>
<note>
<para>
Your CPU type may not include the requisite support for hardware performance counters, in which case
you must use oprofile in RTC mode: see <xref linkend="rtc" />.
</para>
</note>
<para>
The hardware performance counters are detailed in the Intel IA-32 Architecture Manual, Volume 3, available
from <ulink url="http://developer.intel.com/">http://developer.intel.com/</ulink>. The AMD Athlon/Duron
implementation is detailed in <ulink url="http://www.amd.com/products/cpg/athlon/techdocs/pdf/22007.pdf">
http://www.amd.com/products/cpg/athlon/techdocs/pdf/22007.pdf</ulink>.
These processors are capable of delivering an interrupt to the local <acronym>APIC</acronym> <acronym>LVTPC</acronym>
vector when a counter overflows. This is the basic mechanism on which oprofile is based. The kernel module
installs an interrupt handler for this vector. The delivery mode is set to <acronym>NMI</acronym> so that
blocking interrupts in the kernel does not prevent profiling. When the interrupt handler is called,
the current <acronym>EIP</acronym> <acronym>PC</acronym> value, process id, and counter
are recorded into the profiling structure. This allows the overflow event to be attached
to a specific assembly instruction in a binary image. The daemon is necessary to transform these recorded
values into a count against a file offset for a given binary image, in order to produce profile data off-line
at a later time.
</para>
<para>
If we use an event such as <constant>CPU_CLK_UNHALTED</constant> or <constant>INST_RETIRED</constant>
(<constant>GLOBAL_POWER_EVENTS</constant> or <constant>INSTR_RETIRED</constant>, respectively, on the Pentium 4), we can
use the overflow counts as an estimate of actual time spent in each part of code. Alternatively we can profile interesting
data such as the cache behaviour of routines with the other available counters.
</para>
<para>
However there are several caveats. Firstly there are those issues listed in the Intel manual. There is a delay
between the counter overflow and the interrupt delivery that can skew results on a small scale - this means
you cannot rely on the profiles at the instruction level, except as a binary was/wasn't executed indicator.
If you are using an "event-mode" counter such as the cache counters, a count registered against it doesn't mean
that it is responsible for that event. However, it implies that the counter overflowed in the dynamic
vicinity of that instruction, to within a few instructions. Further details on this problem can be found in 
<xref linkend="interpreting" /> and also in
the Digital paper "ProfileMe: A Hardware Performance Counter". Also note that a very high number of interrupts
can have a large performance effect, and even overflow the profiling data structures. This can lead to mapping information
getting overwritten, and loss of respect from boxing promoter (don't worry, an obscure reference). The system
stability will never be affected, but profiling may not be able to work properly. An error message from the
kernel module will appear in your system log files if this situation occurs.
</para>
<para>
As described in the Intel manual, each counter, as well as being configured to count an event type, has several
more configuration parameters. First, there is the unit mask: this simply further specifies what to count.
Second, there is the counter value, discussed below. Third, there is a parameter whether to increment counts
whilst in kernel or user space. You can configure these separately for each counter.
</para>
<para>
So you must specify a counter value with the <option>--ctrX-count</option> option, where <option>X</option>
is the logical counter number in the range 0 to 3 fro AMD Athlon processors, 0 to 1 for
Intel P6 generation procecessors, and 0 to 7 for Intel Pentium 4 processors.
Using multiple counters is useful for profiling several aspects of the same running program.
After each overflow event, the counter will be re-initialized
such that another overflow will occur after this many events have been counted. Picking a good value for this
parameter is, unfortunately, somewhat of a grey art (not quite black). It is of course dependent on the event
you have chosen. For basic time-based profiling, you will probably use <constant>CPU_CLK_UNHALTED</constant>
(on Intel P6 generation processors). 
You can estimate how many interrupts this value will generate per second with this event by dividing your CPU
clock rate by the chosen value. I have a 600MHz Celeron, so specifying an overflow value of 100,000 will generate
around 6000 interrupts per second. Specifying too large a value will mean not enough interrupts are generated
to give a realistic profile (though this problem can be ameliorated by profiling for <emphasis>longer</emphasis>).
Specifying too small a value can lead to overflow problems discussed previously.
</para>

</sect2>

<sect2 id="rtc">
<title>oprofile in RTC mode</title>
<para>
Some CPU types do not provide the needed hardware support to use the hardware performance counters. This includes
some laptops, classic Pentiums, and other CPU types not yet supported by oprofile (such as Cyrix). 
On these machines, oprofile falls
back to using the real-time clock interrupt to collect samples. This interrupt is also used by the <command>rtc</command>
module: you cannot have both the oprofile and rtc modules loaded nor the rtc support compiled in the kernel.
</para>
<para>
RTC mode is less capable than the hardware counters mode; in particular, it is unable to profile sections of
the kernel where interrupts are disabled. There is just one available event, "RTC interrupts", and its value 
corresponds to the number of interrupts generated per second (that is, a higher number means a better profiling
resolution, and higher overhead). The current implementation of the real-time clock supports only power-of-two
sampling rates from 2 to 4096 per second.  Other values within this range are rounded to the nearest power of
two.
</para>
<para>
Setting the value from the GUI should be straightforward. On the command line, you need to specify the
<option>--rtc-value</option> option to <command>opcontrol</command>, e.g. :
</para>
<para><command>opcontrol --setup --vmlinux=/boot/2.4.0ac12/vmlinux --rtc-value=256</command></para>
<para>
Note the sysctl tree described in the next section is different when the RTC is being used.  In particular,
the file <filename>/proc/sys/dev/oprofile/rtc_value</filename> is used by the tools to set the desired RTC 
sampling rate, and will reflect the actual sampling rate after profiling has started.
</para>
</sect2>

<sect2 id="p4">
<title>Pentium 4 support</title>
<para>
The Pentium 4 / Xeon performance counters are organized around 3 types of model specific registers (MSRs): 45 event
selection control registers (ESCRs), 18 counter configuration control registers (CCCRs) and 18 counters. ESCRs describe a
particular set of events which are to be recorded, and CCCRs bind ESCRs to counters and configure their
operation. Unfortunately the relationship between these registers is quite complex; they cannot all be used with one
another at any time. There is, however, a subset of 8 counters, 8 ESCRs, and 8 CCCRs which can be used independently of
one another, so the Oprofile module only accesses those registers, treating them as a bank of 8 "normal" counters, similar
to those in the P6 or Athlon families of CPU.
</para>
<para>
There is currently no support for Precision Event-Based Sampling (PEBS), nor any advanced uses of the Debug Store
(DS). Current support is limited to the conservative extension of Oprofile's existing interrupt-based model described
above.  Performance monitoring hardware on Pentium 4 / Xeon processors with Hyperthreading enabled (multiple logical
processors on a single die) is not supported either.
</para>
</sect2>

<sect2 id="ia64">
<title>Intel Itanium 2 support</title>
<para>
The Itanium 2 performance monitoring unit (PMU) organizes the counters as four
pairs of performance event monitoring registers. Each pair is composed of a
Performance Monitoring Configuration (PMC) register and Performance Monitoring
Data (PMD) register.  The PMC selects the performance event being monitored and
the PMD determines the sampling interval. The IA64 Performance Monitoring Unit
(PMU) triggers sampling with maskable interrupts. Thus, samples will not occur
in sections of the IA64 kernel where interrupts are disabled.
</para>
<para>
None of the advance features of the Itanium 2 performance monitoring unit
such as opcode matching, address range matching, or precise event sampling are
supported by this version of oprofile.  The Itanium 2 support only maps oprofile's
existing interrupt-based model to the PMU hardware.
</para>
</sect2>

<sect2 id="sysctl">
<title><command>sysctl</command> tree</title>
<para>
When the kernel module loads, it generates a file hierarchy underneath <filename>/proc/sys/dev/oprofile</filename>.
You can read and write to these files to give direct access to the kernel parameters.
</para>
<note>
<para>
With the exception of <filename>dump</filename> and <filename>dump_stop</filename>, 
any changes only take effect on restarting the profiler.
</para>
</note>
The following files will be present :
<variablelist>
	<varlistentry>
		<term><filename>bufsize</filename></term>
		<listitem><para>
		The buffer size, corresponding to the <option>--buffer-size</option> option.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>notesize</filename></term>
		<listitem><para>
		The note table size, corresponding to the <option>--note-table-size</option> option.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>kernel_only</filename></term>
		<listitem><para>
		Corresponding to the <option>--kernel-only</option> option.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>dump</filename></term>
		<listitem><para>
		Writing <acronym>ASCII</acronym> "1" to the file will initiate a sample data dump. Note: ignore
		the value "0" you get when reading the file - it is meaningless.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>dump_stop</filename></term>
		<listitem><para>
		Writing to this file will stop the profiler, processing all pending data, and stopping the user-space
		daemon.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>nr_interrupts</filename></term>
		<listitem><para>
		Read only; the number of total interrupts received on all processors since this file was last
		read. Used by the GUI.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>cpu_type</filename></term>
		<listitem><para>
		Read only; used internally by the oprofile tools.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>0, 1, ...</filename></term>
		<listitem><para>
		Each counter will have a directory containing files for that counter's settings.
		The rest of the files described here are per-counter.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>count</filename></term>
		<listitem><para>
		The counter value for this counter.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>enabled</filename></term>
		<listitem><para>
		Whether this counter is active.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>event</filename></term>
		<listitem><para>
		The numeric event value. You can convert from symbolic event names to numeric values like so :
		</para><para><command>echo `op_help CPU_CLK_UNHALTED` &gt;/proc/sys/dev/oprofile/0/0/event</command>.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>kernel</filename></term>
		<listitem><para>
		Whether to profile the kernel.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>unit_mask</filename></term>
		<listitem><para>
		The unit mask specified.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><filename>user</filename></term>
		<listitem><para>
		Whether to profile user-space.
		</para></listitem>
	</varlistentry>
</variablelist>

</sect2>

<sect2 id="misuse">
<title>Misuse of <command>oprofile</command> and stability of system</title>
<para>
oprofile is a low-level profiler which allow continuous profiling with a low-overhead cost.
If not used carefully, this can affect the stability of the system.
If too low a count reset value is set for a counter, the system can become overloaded with counter
interrupts, and seem as if the system has frozen.
</para>
<note><para>
This can happen as follows: When the profiler count
reaches zero an NMI handler is called which stores the sample values in an internal buffer, then resets the counter
to its original value. If the count is very low, a pending NMI can be sent before the NMI handler has
completed. Due to the priority of the NMI, the local APIC delivers the pending interrupt immediately after
completion of the previous interrupt handler, and control never returns to other parts of the system.
In this way the system seems to be frozen.
</para></note>
<para>If this happens, it will be impossible to bring the system back to a workable state.
There is no way to provide real security against this happening, other than making sure to use a reasonable value
for the counter reset. For example, setting CPU_CLK_UNHALTED event type with a ridiculously low reset count (e.g. 500)
is likely to freeze the system.
</para>
<para>
In short : <command>Don't try a foolish sample count value.</command> Unfortunately the definition of a foolish value
is really dependent on the event type - if ever in doubt, e-mail </para>
<address><email>oprofile-list@lists.sf.net</email>.</address>
<para>Do I hear you shout "but my event value is low, but not stupid !" ? Yes, this can be the case. In these
circumstances, a simple solution is to disable kernel profiling by turning off the kernel option for
each enabled counter. As the NMI handler is in-kernel, this avoids the problem.
</para>

</sect2>

</sect1>
 
<sect1 id="other-features">
<title>Other features</title>

<sect2 id="pidpgrpfilter">
<title>pid/pgrp filter</title>
<para>There are situations where you are only interested in the profiling results of a particular
running process, or process tty group. You can set
the pid/pgrp values via the <filename>--pid-filter</filename> and <filename>--pgrp-filter</filename>
options to <command>opcontrol --setup</command>, which will make the daemon ignore samples for processes
that don't match the filter.
</para>
</sect2>

<sect2 id="unloadable">
<title>Unloading the kernel module</title>
<para>
The kernel module can be unloaded, but is designed to take very little memory when profiling is not underway.
There is no need to unload the module between profiler runs.
</para>
<para>
<command>lsmod</command> and similar utilities will still show the module's use count as <constant>-1</constant>.
However, this is not to be relied on - the module will become unloadable some short time after stopping profiling.
</para>
<para>
Note that by default module unloading is disabled when used on SMP systems. This is because of a small
chance of a module unload race crashing the kernel. As the race is very small, it is allowed to
re-enable the module unload by specifying the "allow_unload" parameter to the module :
</para>
<para><command>modprobe oprofile allow_unload=1</command></para>
<para>This option can be <emphasis>DANGEROUS</emphasis> and should only be used on non-production systems.</para> 
</sect2>

</sect1>
 
</chapter>

<chapter id="results">
<title>Obtaining results</title>
<para>
OK, so the profiler has been running, but it's not much use unless we can get some data out. Fairly often,
oprofile does a little <emphasis>too</emphasis> good a job of keeping overhead low, and no data reaches
the profiler. This can happen on lightly-loaded machines. Remember you can force a dump at any time with :
</para>
<para><command>opcontrol --dump</command></para>
<para>Remember to do this before complaining there is no profiling data !
Now that we've got some data, it has to be processed. That's the job of <command>oprofpp</command> or <command>op_to_source</command>.
This works on a sample file in the <filename>/var/lib/oprofile/samples/</filename> directory,
along with the binary file being profiled, to produce human-readable data. Note that if the binary file changes
after the sample file was created, you won't be able to get useful data out. This situation is detected for you.
Note that several instances of a binary are merged into one sample file. By default, all samples from a dynamically linked library
are merged into one sample file as well.
</para>
<para>
A different scenario happen when re-starting profiling with different parameters, as the old sample files from previous sessions don't
get deleted (allowing you to build profiles over many distinct profiling sessions).
If the last session is determined to be out of date due to the use of different profiling parameters, all the samples files are
backed up in a sub-directory name session-#nr.
If during profiling the daemon detects a change to a binary image and a samples file belonging to this binary exists, the samples file is silently deleted.
So if during profiling you change a binary it is your responsibility to save the binary image <emphasis>and</emphasis> the samples files, if 
you need it.
</para>
<para>
Note that kernel modules without symbol data (this can happen with some initrd setups) cannot be profiled (modules
with symbols show up in <filename>/proc/ksyms</filename>).
</para>

<sect1 id="post-profile-tools-common-options">
<title>common options to post-profile tools</title>
<para>
All post profile tools accept the following options
</para>
<variablelist>
	<varlistentry>
		<term><option>--help</option></term>
		<term><option>--usage</option></term>
		<term><option>-?</option></term>
		<listitem><para>
		Show the command line options.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--version</option></term>
		<term><option>-v</option></term>
		<listitem><para>
		Show the version number of oprofile on the form:
		</para>
<screen>
app_name:  oprofile 0.1cvs compiled on Mar  1 2002 20:40:40
</screen>
		</listitem>
	</varlistentry>
</variablelist>
</sect1>

<sect1 id="post-profiler">
<title><command>oprofpp</command> usage</title>
<para>
Oprofpp can be used in three major modes; list symbol mode, detailed symbol mode, or <command>gprof</command> mode.
The first gives sorted histogram output of sample counts against functions as shown in the walkthrough. The second
can show individual sample counts against instructions inside a function, useful for detailed profiling, whilst the
third mode is handy if you're used to <command>gprof</command> style output. Note that only flat <command>gprof</command>
profiles are supported, however.
</para>
<para>
Some interesting options of the post-processor :
</para>
<variablelist>
	<varlistentry>
		<term><option>--samples-file</option> <filename>filename</filename></term>
		<term><option>-f</option> <filename>filename</filename></term>
		<listitem><para>
		The samples file to use. By default, the current samples file for the given binary is used;
		this option can be used to examine older sample files.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--image-file</option> <filename>filename</filename></term>
		<term><option>-i</option> <filename>filename</filename></term>
		<listitem><para>
		The binary image (shared library, kernel vmlinux, or program) to produce data for.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--demangle</option></term>
		<term><option>-d</option></term>
		<listitem><para>
		Demangle C++ symbol names.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--counter</option> nr</term>
		<listitem><para>
		Which counter (0 - N) to extract information for. N is dependent on your cpu type: 1 for P6 generation CPUs, 
		3 for Athlon based CPUs, 8 for Pentium 4 / Xeon CPUs.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--list-symbols</option></term>
		<term><option>-l</option></term>
		<listitem><para>
		List a histogram of sample counts against symbols. Each line shows the function name,
		its starting address, the relative percentage of hits across that image, and the absolute
		number of samples in this function.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--list-symbol</option> name</term>
		<term><option>-s</option> name</term>
		<listitem><para>
		Provide a detailed listing for the specified symbol name. This shows, for each sample,
		the position of the address, and the number of samples.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--dump-gprof-file filename</option></term>
		<term><option>-g filename</option></term>
		<listitem><para>
		Dump output to the specified file in <command>gprof</command> format. If you specify <filename>gmon.out</filename>,
		you can then call <command>gprof -p &lt;binary&gt;</command>.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--list-all-symbols-details</option></term>
		<term><option>-L</option></term>
		<listitem><para>
		Provide a detailed listing for all symbols. Each line shows number of samples at the given
		address for all counters.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--output-linenr-info</option></term>
		<term><option>-o</option></term>
		<listitem><para>
		Show the function and line number for all samples. This requires that the image was compiled
		with debug symbols (<option>-g</option>), and is
		usable only with --list-all-symbols-details, --list-symbol and --list-symbols.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--exclude-symbol</option> symbol[,symbol]</term>
		<term><option>-e</option> symbol[,symbol]</term>
		<listitem><para>
		Comma-separated list of symbols to ignore. This can be useful to ignore the leading contributors
		to the sample histogram, as the percentage values are re-calculated.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--show-shared-libs</option></term>
		<term><option>-k</option></term>
		<listitem><para>
		Show the details for each shared lib which belongs to the given application. This option is useful only
		if you have profiled with the <option>--separate-samples</option> option and you specify on the
		oprofpp command line either <option>--list-symbols</option> or 
		<option>--list-all-symbols-details</option>.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--output-format</option> vsSpPqQnlLiIh</term>
		<term><option>-t</option> vsSpPqQnlLiIh</term>
		<listitem><para>
		Specify the output format where a single format char is a field intended for: 'v' vma, 's'
		nr samples, 'S' nr cumulated samples, 'p' percent samples, 'P' cumulated percent samples,
		'n' symbol name, 'l' source file name and line nr, 'L' ditto as 'l' but with basename of source
		file name, 'i' image name, 'I' ditto as 'i' but with base name of image name, 'd' details for each samples for
		the selected symbols and 'h' for the header itself. 'q','Q' are identical to 'p', 'P' but the
		percentage are relative to the total number of symbols.
		This option is not available with --dump-gprof-file.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--session</option> session-name</term>
		<listitem><para>
		Specify the session name you want to use, session-name can be an absolute path
		where samples reside or a session name relative to samples files base directory.
		If you specify a samples filename with an absolute path this option is ignored
		</para></listitem>
	</varlistentry>
</variablelist>

</sect1>

<sect1 id="op-to-source">
<title><command>op_to_source</command>: Outputting annotated source</title>
<para>
<command>op_to_source</command> generates annotated source files or assembly listings optionally mixed with source.
If you want to see the source file the profiled application needs to have debug information and the source
must be available through this debug information e.g. compile the application with <option>-g</option> for 
<command>gcc</command>. If the binary don't contain sufficient debug info you can use <command>op_to_source <option>--assembly</option></command> to get assembly annotation. See the FAQ <xref linkend="symbol-and-debug-info" /> about debug information vs symbol information.
</para>
<para>
Note that for the reason explained in <xref linkend="hardware-counters" /> the results can show some
inaccuracy. The debug info itself can add other problems; for example, the line number for a symbol can be
incorrect. Assembly instructions can be re-ordered and moved by the compiler, and this can lead to
crediting source lines with samples not really "owned" by this line. Also see
<xref linkend="interpreting" />.
</para>
<para>
The options allowed are :
</para> 
<variablelist>
	<varlistentry>
		<term><option>--assembly</option></term>
		<term><option>-a</option></term>
		<listitem><para>
		<!-- FIXME: update if this changes -->
		Output assembly code. Currently the assembly code is sorted in increasing order on the vma
		address. The <option>--sort-by-counter</option>, <option>--with-more-than-samples percent_nr</option> and
		<option>--until-more-than-samples percent_nr</option> options can also be used with this
		option to provide filtering capabilities.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--source-dir</option> <filename>dirname</filename></term>
		<listitem><para>
		This option is used in conjunction with <option>--output-dir</option>. You
		can use it to specify the base directory of the source which you wish to produce
		annotated output for. With this option, any source files outside the directory
		(for example, system header files) are ignored.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--output-dir</option> <filename>dirname</filename></term>
		<listitem><para>
		Specify that you want to produce an annotated source tree, rather than getting all output to stdout. This
		creates a hierarchy of annotated source files, and is affected by the <option>--source-dir</option>,
		<option>--output</option>, and <option>--no-output</option> options.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--output patterns</option></term>
		<listitem><para>
		Specify a set of comma-separated patterns for matching annotated source output filenames.
		If this option is present, a file is only output if it matches one of the given
		patterns (which applies to the filename and each components of the containing directory names).
		For example :
		</para>
		<para>
		<command>--output '*.c,user.h'</command>
		</para>
		</listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--no-output patterns</option></term>
		<listitem><para>
		Specify a set of comma-separated patterns for filtering annotated source output filenames.
		If this option is present, a file is only output if it does not match one of the given
		patterns (which applies to the filename and each components of the containing directory names).
		For example :
		</para>
		<para>
		<command>--no-output 'boring.c,boring*.h'</command>
		</para>
		</listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--source-with-assembly</option></term>
		<term><option>-s</option></term>
		<listitem><para>
		Output assembly code mixed with the source file, implies <option>--assembly</option>.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--objdump-params</option></term>
		<term><option>-o</option></term>
		<listitem><para>
		Pass the comma separated additional parameters to objdump. Check the objdump man page
		to see what options objdump accept e.g. <option>-o '--disassembler-options=intel'</option>
		to get Intel assembly syntax instead of att syntax. This option can be used only with
		<option>--assembly</option> or <option>--source-with-assembly</option>
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--sort-by-counter counter_nr</option></term>
		<term><option>-c counter_nr</option></term>
		<listitem><para>
		Sort by decreasing number of samples on counter_nr. For assembly output this option provides only
		a filtering and not a sort order.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--with-more-than-samples percent_nr</option></term>
		<term><option>-w percent_nr</option></term>
		<listitem><para>
		Output source file which contains at least <option>percent_nr</option> samples.
		Can not be combined with <option>--until-more-than-samples</option>.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--until-more-than-samples percent_nr</option></term>
		<term><option>-m percent_nr</option></term>
		<listitem><para>
		Output source files until the amount of samples in these files reach percent_nr samples.
		Can not be combined with <option>--with-more-than-samples</option>.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--samples-file</option> <filename>filename</filename></term>
		<term><option>-f</option> <filename>filename</filename></term>
		<listitem><para>
		Specify the samples file. At least one of the <option>--samples-file</option> or
		<option>--image-file</option> must be specified.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--image-file</option>  <filename>filename</filename></term>
		<term><option>-i </option>  <filename>filename</filename></term>
		<listitem><para>
		Specify the image file.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--exclude-symbol</option> symbol[,symbol]</term>
		<term><option>-e</option> symbol[,symbol]</term>
		<listitem><para>
		Comma-separated list of symbols to ignore. This can be useful to ignore the leading contributors
		to the sample histogram, as the percentage values are re-calculated.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--include-symbol</option> symbol[,symbol]</term>
		<term><option>-y</option> symbol[,symbol]</term>
		<listitem><para>
		Comma-separated list of symbols to include. This can be useful to only see the leading contributors
		to the sample histogram, as the percentage values are re-calculated.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--session</option> session-name</term>
		<listitem><para>
		Specify the session name you want to use, session-name can be an absolute path
		where samples reside or a session name relative to samples files base directory.
		If you specify a samples filename with an absolute path this option is ignored
		</para></listitem>
	</varlistentry>
</variablelist>
</sect1>

<sect1 id="op-merge">
<title><command>op_merge</command>: merging samples files</title>
<para>
<command>op_merge</command> is used to merge samples wich belongs to the same binary image. Its main purpose
is to merge samples files created by profiling with --separate-samples. So you can create one samples
file containing all samples for a shared libs:
<command>op_merge</command><filename>/usr/lib/ld-2.1.2.so</filename> will create a samples file named
<filename>}usr}lib}ld-2.1.2.so</filename> ready to use with <command>oprofpp</command> or other post-profiling tools.
Additionally you can merge a subset of samples files inside one sample file by specifying explicitly the samples files name to merge.
This allows to use post-profile tools on shared libs for a subset of applications.
</para>
<para>
The options allowed are :
</para>
<variablelist>
	<varlistentry>
		<term><option>--use-counter</option> nr</term>
		<term><option>-c</option></term>
		<listitem><para>
		use counter nr to select the appropriate samples files
		</para></listitem>
	</varlistentry>
</variablelist>
</sect1>

<sect1 id="op-time">
<title><command>op_time</command>: Overall view of all system binaries</title>
<para>
You can get a quick look at an overall summary of relative binary profiles using <command>op_time</command>. This utility displays
the relative amount of samples for each application profiled sorted by decreasing order of samples count. So
with <command>op_time [<option>--option</option>] [<filename>image_name[,image_names]</filename>]</command> you can get :
</para>
<screen>
/lib/libc-2.1.2.so 19 32.7586%
/usr/X11R6/bin/XF86_SVGA 13 22.4138%
...
/usr/bin/grep 1 1.72414%
/usr/X11R6/lib/libXt.so.6.0 1 1.72414%
</screen>
<para>
If you don't specify any image_name on command line op_time report information about all profiled binary image.
You can use shell wildcards like :
<command>op_time <filename>/usr/bin/*</filename></command>
</para>
<para>
Options allowed are :
</para> 
<variablelist>
	<varlistentry>
		<term><option>--use-counter</option> nr</term>
		<term><option>-c</option></term>
		<listitem><para>
		use counter nr for sorting samples count
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--show-shared-libs</option></term>
		<term><option>-k</option></term>
		<listitem><para>
		Show the details for each shared lib which belongs to one application. This option is
		useful only if you have profiled with the <option>--separate-samples</option> option.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--list-symbols</option></term>
		<term><option>-l</option></term>
		<listitem><para>
		Show details for each symbols in each profiled files
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--demangle</option></term>
		<term><option>-d</option></term>
		<listitem><para>
		demangle GNU C++ symbol names
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--show-image-name</option></term>
		<term><option>-n</option></term>
		<listitem><para>
		show the image name when specifying <option>--list-symbols</option>
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--reverse</option></term>
		<term><option>-r</option></term>
		<listitem><para>
		Sort by decreasing samples count instead of increasing count.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--path</option> path list ',' separated</term>
		<term><option>-p</option> path list ',' separated</term>
		<listitem><para>
		Specify an alternate list of pathname to locate image file. This is usefull if your samples files
		name does not match the image file name such as module loaded at boot time through a ram disk
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--recursive-path</option> path list ',' separated</term>
		<term><option>-P</option> path list ',' separated</term>
		<listitem><para>
		Same as <option>mdash;</option> but retrieve recursively the image file name in the path list
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--output-format</option> vsSpPnlLiIh</term>
		<term><option>-t</option> vsSpPnlLiIh</term>
		<listitem><para>
		Specify the output format where a single format char is a field intended for: 'v' vma, 's'
		nr samples, 'S' nr cumulated samples, 'p' percent samples, 'P' cumulated percent samples,
		'n' symbol name, 'l' source file name and line nr, 'L' ditto as 'l' but with basename of source
		file name, 'i' image name, 'I' ditto as 'i' but with base name of image name, 'd' details for each samples for
		the selected symbols and 'h' for the header itself.
		This option is available only with --list-symbols
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--exclude-symbol</option> symbol[,symbol]</term>
		<term><option>-e</option> symbol[,symbol]</term>
		<listitem><para>
		Comma-separated list of symbols to ignore. This can be useful to ignore the leading contributors
		to the sample histogram, as the percentage values are re-calculated.
		</para></listitem>
	</varlistentry>
	<varlistentry>
		<term><option>--session</option> session-name</term>
		<listitem><para>
		Specify the session name you want to use, session-name can be an absolute path
		where samples reside or a session name relative to samples files base directory.
		</para></listitem>
	</varlistentry>
</variablelist>
</sect1>
</chapter>

<chapter id="interpreting">
<title>Interpreting profiling results</title>
<para>
Another grey art. The standard caveats of profiling come
to mind: profile realistic situations, profile difference scenarios, profile
for as long as a time as possible, avoid system-specific artifacts, don't trust
the profile data too much. Also bear in mind the comments on the performance
counters above - you can <emphasis>not</emphasis> rely on totally accurate
instruction-level profiling.  However, for almost all circumstances the data
can be useful. Ideally a utility such as Intel's VTUNE would be available to
allow careful instruction-level analysis; go hassle Intel for this, not me ;)
</para>
<sect1 id="irq-latency">
<title>Profiling interrupt latency</title>
<para>
This is an example of how the latency of delivery of profiling interrupts
can impact the reliability of the profiling data. This is pretty much a 
worst-case-scenario example: these problems are fairly rare.
</para>
<screen>
double fun(double a, double b, double c)
{
 double result = 0;
 for (int i = 0 ; i &lt; 10000; ++i) {
  result += a;
  result *= b;
  result /= c;
 }
 return result;
}
</screen>
<para>
Here the last instruction of the loop is very costly, and you would expect the result
reflecting that - but (cutting the instructions inside the loop):
</para>
<screen>
$ op_to_source -a -w 10

 /* 9349 0.3788% */
 8048394:       fadd   %st(3),%st
 /* 22858 0.9261% */
 8048396:       fmul   %st(2),%st
 /* 687682 27.86% */
 8048398:       fdiv   %st(1),%st
 /* 1747822 70.81% */
 804839a:       decl   %eax
 /* 17 0.0006887% */
 804839b:       jns    8048394
</screen>
<para>
The problem comes from the x86 hardware; when the counter overflows the IRQ line
is asserted but the hardware have features that can delay the NMI interrupt:
x86 hardware is synchronous (e.g. can not interrupt during an instruction but
interrupt at the end of instruction), there is also a latency when the IRQ
line is asserted the hardware can take some cycles to get account; the multiple
execution unit and the out of order model of modern x86 family also causes
problems. The following shows the same function at source level
</para>
<screen>
$op_to_source -a -w 10 show

double fun(double a, double b, double c)
/* fun(double, double, double) 2468162 100% */
/* 165 0.006685% */
{
        /* 3 0.0001215% */
        double result = 0;
        for (int i = 0 ; i &lt; 10000; ++i) {
                /* 9349 0.3788% */
                result += a;
                /* 22858 0.9261% */
                result *= b;
                /* 687682 27.86% */
                result /= c;
        /* 1747918 70.82% */
        }
        return result;
/* 187 0.007576% */
}
</screen>
<para>
So the conclusion: don't trust samples coming at the end of a loop,
particularly if the last instruction generated by the compiler is costly, this
case can occur also for each branch in your program. Always bear in mind that samples
can be often delayed by a few cycles from its real position. That's a hardware
problem and oprofile can do nothing about it.
</para>
</sect1>
<sect1 id="irq-masking">
<title>Interrupt Masking</title>
<para>
oprofile uses non-maskable interrupts (NMI) on the P6 generation, Pentium 4,
Athlon and Duron processors. These interrupts can occur even in section of the
Linux where interrupts are disabled, allowing collection of samples in virtually
all executable code.  The RTC and Itanium 2 collection mechanisms use maskable
interrupts. Thus, the RTC and Itanium 2 data collection mechanism have "sample
shadows", regions where no samples where be collected. Typically, the samples
will be attributed to the code immediately after the interrupt are re-enabled.
</para>
</sect1>
<sect1 id="debug-info">
<title>Inaccuracies in annotated source</title>
<sect2 id="effect-of-optimizations">
<title>side effects of optimizations</title>
<para>
The compiler can introduce some pitfalls in the annotated source output.
The optimizer can move pieces of code in such manner that two line of codes
are interlaced (instruction scheduling). Also debug info generated by the compiler 
can show strange behavior. This is especially true for complex expressions e.g. inside
an if statement:
</para>
<screen>
	if (a &amp;&amp; ..
	    b &amp;&amp; ..
	    c &amp;&amp;)
</screen>
<para>
here the problem come from the position of line number. The available debug
info does not give enough details for the if condition, so all samples are
accumulated at the position of the right brace of the expression. Using
<command>op_to_source <option>-a</option></command> can help to show the real
samples at an assembly level.
</para>
</sect2>
<!--
 FIXME This is not sufficient find examples
<sect2 id="inlined-function">
<title>inlined functions</title>
<para>
In some language the compiler can generate implicitely functions such as copy
constructor or copy operator in C++. Such function are credited by the compiler
of a zero line number which give weirds annotation.
</sect2>
</para>
</sect2>
-->
<sect2 id="wrong-linenr-info">
<title>inaccuracy in line number information</title>
<para>
Depending on your compiler you can fall into the following problem:
</para>
<screen>
struct big_object { int a[500]; };

int main()
{
	big_object a, b;
	for (int i = 0 ; i != 1000 * 1000; ++i)
		b = a;
	return 0;
}

</screen>
<para>
Compiled with <command>gcc</command> 3.0.4 the annotated source is clearly inaccurate:
</para>
<screen>
int main()
{
        big_object a, b;
/* main 7871 100% */
        for (int i = 0 ; i != 1000 * 1000; ++i)
                b = a;
        /* 7871 100% */
        return 0;
}
</screen>
<para>
The problem here is distinct from the irq latency problem, the debug line number
info are not enough precise, again looking at output of <command>op_to_source -as</command> can help.
</para>
<screen>
/* 7871 100% */
int main()
{
        big_object a, b;
        for (int i = 0 ; i != 1000 * 1000; ++i)
 80484c0:       push   %ebp
 80484c1:       mov    %esp,%ebp
 80484c3:       sub    $0xfac,%esp
 80484c9:       push   %edi
 80484ca:       push   %esi
 80484cb:       push   %ebx
                b = a;
 80484cc:       lea    0xfffff060(%ebp),%edx
 80484d2:       lea    0xfffff830(%ebp),%eax
 80484d8:       mov    $0xf423f,%ebx
 80484dd:       lea    0x0(%esi),%esi
        return 0;
 /* 3 0.03811% */
 80484e0:       mov    %edx,%edi
 80484e2:       mov    %eax,%esi
 /* 1 0.0127% */
 80484e4:       cld
 /* 8 0.1016% */
 80484e5:       mov    $0x1f4,%ecx
 /* 7850 99.73% */
 80484ea:       repz movsl %ds:(%esi),%es:(%edi)
 /* 9 0.1143% */
 80484ec:       dec    %ebx
 80484ed:       jns    80484e0
 80484ef:       xor    %eax,%eax
 80484f1:       pop    %ebx
 80484f2:       pop    %esi
 80484f3:       pop    %edi
 80484f4:       leave
 80484f5:       ret
</screen>
<para>
So here it's clear than copying is correctly credited of all samples but the
line number info are misplaced. <command>objdump -dS</command> expose also the
same problem. Note than maintaining accurate debug info for compilers when optimizing is difficult so this problem is not suprising. The problem of debug info
accuracy is also dependant of the binutils used, some bfd libraries version
contains work-around against known problem of gcc, some other not. This is unfortunate but we must live with that.
Obviously the generally used advise: do not optimize when using debug info is here inapplicable because you want to profile optimized code.
</para>
</sect2>
</sect1>
<!-- FIXME: the wording is perhaps awkward for this section -->
<!-- FIXME: an entry of the FAQ must point here ? -->
<sect1 id="symbol-without-debug-info">
<title>Assembly function</title>
<para>
Often assembler can not generate debug information automatically. Such example of commonly used assembler is
<command>gas</command> and <command>nasm</command>. This means than you can not get source report unless 
you manually define the neccessary debug information, report to your assembler documentation for that. The only
debugging info needed currently by oprofile is the linenr/filename vma association. When profiling assembly
without debugging info you can always get report for symbol and optionnaly for vma through <command>oprofpp -l</command>
or <command>oprofpp -L</command> but this work only for symbol with the right attribute.
For gas you can get this by
</para>
<screen>
.globl foo
	.type	foo,@function
</screen>
<para> 
while for nasm you must use
</para>
<screen>
	  GLOBAL foo:function		; [1]
</screen>
<para>
Note than oprofile do not need the global attribute, but only the function attribute. User of gas and nasm
must found the right way to not declare the foo symbol global if necessary.
</para>
</sect1>
<!-- 

FIXME: I commented this bit out until we've written something ...

improve this ? but look first why this file is special 
<sect2 id="small-functions">
<title>Small functions</title>
<para>
Very small functions can show strange behavior. The file in your source
directory of oprofile <filename>$SRC/test-oprofile/understanding/puzzle.c</filename>
show such example
</para>
</sect2>
--> 
<sect1 id="hidden-cost">
<title>Other discrepancies</title>
<para>
Another cause of apparent problems is the hidden cost of instructions. A very
common example is two memory reads: one from L1 cache and the other from memory.
It's clear for all people than the second memory read will show more samples
but there are many other causes of hidden cost of instructions. A non-exhaustive
list: mis-predicted branch, TLB cache miss, partial register stall,
partial register dependencies, memory mismatch stall, re-executed ops. If you want to write
programs at assembly level, or you write compiler take a look at the Intel and
AMD documentation at <ulink url="http://developer.intel.com/">http://developer.intel.com/</ulink>
and <ulink url="http://www.amd.com/products/cpg/athlon/techdocs/">http://www.amd.com/products/cpg/athlon/techdocs/</ulink>.
</para>
</sect1>
<!-- 

FIXME: we should document how samples can be lost by the daemon, and why not to worry
 
FIXME: more examples, basic and advanced trick. A howto use utilities FAQ ?

The FAQ must use <sect1> and imbricated <sect2> to fit in only one page.
It is possible through release to put the FAQ (or the whole doc ?) on sourceforge ?

yes, indeed. We can do this bit by bit though, as long as we've done as much
as we can for release 1.0 - john
 
List for how to :

o how to get library samples (separate-samples) 
o how to get module / kernel post-prof
o how to use sudo (and risks !)
o more ...
 
<sect2 id="none">
<title>and more</title>
<para>
</para>
</sect2>
--> 
</chapter>

<chapter id="overhead">
<title>Profiling overhead</title>
<para>
One of the major design criterion for oprofile was low overhead. In many cases
profiling is hardly noticeable in terms of overhead (I regularly leave it turned on
all the time). It achieves this by judicious use of kernel-side data structures
to reduce the analysis overhead to a bare runtime minimum. There are several things
that unfortunately complicate the issue, so there are cases where the overhead is
noticeable.
</para>
<para>
The worst-case scenario is where there are many short-lived processes. This can be seen
in a kernel compile, for instance. This leads to a lot of syscall interception. Even in this worst case overhead
is low compared to other profilers; only very detailed profiling of these workloads
has an overhead of higher than 5%. Actual performance
data is presented in the source distribution. In fact most situations have much fewer
numbers of processes, leading to far better performance.
</para>
<para>Some graphs of performance characteristics of oprofile are available on the website
 - see <xref linkend="resources" />.
</para>
</chapter>

<chapter id="FAQ">
<title>FAQ</title>

<!--

FIXME: I tried to use <sect1>...<sect2> to ensure sourceforge FAQ will go on
only one html page but <xref linkend="symbol-and-debug-info" /> are showed as: 
"See Section 1.1"  whilst I expected "See Section 7.1.1" or 
"See Chapter 7 section 1.1"
And currently I get the same problem <xref linkend="symbol-and-debug-info" />
is showed as "See section 1" ...

-->

<sect1 id="symbol-and-debug-info">
<title>Symbol information vs debug information. Why I see (no symbol) in profiling report ?</title>
<para>
Some post-profile tools need only symbol information like basic use of <command>oprofpp</command> whilst
other need debugging information like <command>op_to_source</command>. The notion of debugging information and symbol
information are orthogonal. <command>gcc</command> always create symbol information even without <option>-g</option>.
You must be aware than <command>strip</command> by default remove debug <emphasis>and</emphasis> symbol information. You must use
<command>strip <option>-d</option></command> to strip only debug but symbol information. Profiling binary
without symbol information leads to a lot of (no symbol) reported by <command>oprofpp</command>.
</para>
<para>
Don't think post-profile tools can use dynamic symbol for shared library. These symbol are never stripped but
using them conduct to wrong profling report. Dynamic symbol don't provide enough information to create accurate
profiling report because the symbol size information is lost and so on we don't know if a sample go to an exported
function or to a static function which come immediatly after this exported symbol.
</para>
<para>
In short if you want to profile already installed binary on your system, reinstall them with the proper information,
at least with symbol information for basic <command>oprofpp</command> and <command>op_time <option>-l</option></command> or with full
debug information to get annotated source. Unhopefully debug information can be very voluminous and the neeeded debug
information for annotated source, line numbers, are only generated at <option>-g2</option> level.
</para>
</sect1>

</chapter>

<chapter id="ack">
<title>Acknowledgments</title>
<para>
Thanks to (in no particular order) : Arjan van de Ven, Rik van Riel, Juan Quintela, Philippe Elie,
Phillipp Rumpf, Tigran Aivazian, Alex Brown, Alisdair Rawsthorne, Bob Montgomery, Ray Bryant, H.J. Lu,
Jeff Esper, Will Cohen, Graydon Hoare, Cliff Woolley, Alex Tsariounov, Al Stone,
Richard Reich (rreich@rdrtech.com), Dave Jones, Charles Filtness; and finally Pulp, for "Intro".
</para>
</chapter>

</book>
